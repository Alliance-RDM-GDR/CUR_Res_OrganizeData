---
title: "Handling and organizing research data"
subtitle: "A primer for researchers"

author: 
  - name: Daniel Manrique-Castano, Ph.D
    email: daniel.manrique-castano@alliancecan.ca
    affiliations:
      - name: Digital Research Alliance of Canada

format: 
  html:
    link-external-newwindow: true
    embed-resources: true
    mermaid:
      theme: forest
      
  revealjs:
    footer: "Handling and organizing research data - Daniel Manrique-Castano, Ph.D"
    logo: "images/alliance_logo.png"
    theme: white
    transition: fade
    slide-number: true
    show-slide-number: all
    preview-links: auto
    mermaid:
      theme: forest
      mermaid-format: svg
    
filters:
  - reveal-auto-agenda
auto-agenda:
  bullets: numbered
  heading: Agenda
  
  gfm:
    mermaid-format: svg

css: styles.css
bibliography: references.bib 
editor: source
---

# Principles for handling research data

## Make datasets understandable

:::::{layout-ncol="2" layout-valign="center"}
::::{#first-column}
:::{style="text-align: left;font-size: 80%"}
Research data comes in many tastes and shapes ([tables]{style="color:orange;"}, [images]{style="color:magenta;"}, [videos]{style="color:red;"}, [text]{style="color:gray;"}).

In all cases, it is essential that the dataset has a clear [structure]{style="color:green;"} and is [understandable]{style="color:green;"} by others.
:::

::: callout-tip 
Try to put yourself in the shoes of an [outside observer]{style="color:green;"} when structuring the data.
:::
::::

:::: {#second-column}
::: {style="text-align: center; font-size: 70%"}
![Others generally do not understand research data](images/DificultData.webp){fig-alt="A black-and-white cartoon illustration of a frustrated person holding their head, surrounded by question marks. The person is sitting at a table covered with large, disorganized spreadsheets filled with numbers and text, symbolizing the challenge of managing and understanding research data." fig-align="center" width="450" height="450"}
:::
::::
:::::

## 1. Use naming conventions{.center} 

Use consistent [naming conventions](https://datamanagement.hms.harvard.edu/plan-design/file-naming-conventions) that fairly describe file's content and allow interrelation between files:

-   {{< bi card-image>}} [A1.tif]{style="color:red;"} {{< bi arrow-right>}} [Exp_MouseID_Day_Condition_Marker.tif]{style="color:green;"}
-   {{< bi file-earmark-spreadsheet>}} [CellsTable.xls]{style="color:red;"} {{< bi arrow-right>}} [Widefield_5x_Cortex_NeuN_Counts.csv]{style="color:green;"}


## 2. Prioritize open file formats{.center}

Use [proper, open/accessible]{style="color:green;"} [file formats](https://osf.io/ena5p) to improve accessibility:

-   {{< bi card-image>}} [.tif]{style="color:green;"} for images (preserve the metadata).
-   {{< bi file-earmark-spreadsheet>}} [.csv]{style="color:green;"} for tables (non-proprietary).
-   {{< bi file-bar-graph-fill>}} [.png or .svg]{style="color:green;"} for graphs (preserves quality).
-   {{< bi file-earmark-pdf-fill>}} [.txt or .pdf]{style="color:green;"} for documentation (non-proprietary).


## 3. Provide comprehensive metadata{.center}

Use [comprehensive metadata]{style="color:green;"} (README files and data dictionaries/codebook) to [contextualize]{style="text-decoration: underline;"} and [describe]{style="text-decoration: underline;"} research files.

:::{style="text-align: center; font-size: 70%"}
![Codebook example (https://domstat.med.ucla.edu/)](images/Codebook.jpg){fig-alt="A table displaying a codebook for a dataset, with columns labeled 'Variable Name,' 'Description,' 'Type,' and 'Values or Characteristics.' The table defines variables such as patient ID, gender, procedure date, treatment group, and clinical outcomes, specifying data types (numeric, date, character) and value meanings (e.g., 1=Female, 2=Male). This codebook provides a structured overview of dataset variables for research data management."    fig-align="center" width="500" height="300"}
:::

## 4. Implement reproducible workflows{.center}

Implement [reproducible workflows]{style="color:green;"} using coding (R, Python) to transform [raw data]{style="text-decoration: underline;"} into data for [analysis]{style="text-decoration: underline;"}.

::: callout-tip
These practices ensure [organized, clean, and validated]{style="color:green;"} datasets.
:::


# Handling data tables

## {{< bi file-earmark-spreadsheet>}} Tables are the core of scientific data {.center}

::: {style="text-align: left;font-size: 70%"}
Despite being the most common file type (.xls) for recording/storing data, tables are the most [poorly organized and unusable]{style="color:red;"} objects in research.
:::

::::: {layout-ncol="2"}
:::: {#first-column}
::: {style="text-align: center;font-size: 50%"}
![from https://dansteer.wordpress.com/](images/BadTable1.webp){fig-alt="Example of bad data formatting, showcasing a spreadsheet with combined cells and different variables in the same column." fig-align="center" width="600" height="300"}
:::
::::

:::: {#second-column}
::: {style="text-align: center;font-size: 50%"}
![Courtesy of researcher](images/BadTable2.png){fig-alt="Example of bad data formatting, showcasing a spreadsheet with combined cells and different variables in the same column. We can also observe a combination of figures and numeric data in the same sheet."  fig-align="center" width="600" height="300"}
:::
::::
:::::

## Examples from published research{.center}

::::: {layout-ncol="2"}
:::: {#first-column}
::: {style="text-align: center;font-size: 50%"}
![Zhao et al. (2024). Nature Comm. DOI: 10.1038/s41467-024-50836-6](images/BadTable2_Zhao(2024)_NatureComm.png){fig-alt="Example of bad data formatting, showcasing a spreadsheet with combined cells and different variables in the same column. We can also observe a combination of figures and numeric data in the same sheet." fig-align="center" width="400" height="400"}
:::
::::

:::: {#second-column}
::: {style="text-align: center;font-size: 50%"}
![Balinda et al. (2024). Nature Comm. DOI: doi.org/10.1038/s41467-024-50558-9](images/BadTable2_Balinda(2024)_NatureComm.png){fig-alt="Example of bad data formatting, showcasing a spreadsheet with combined cells and different variables in the same column. We also see color codes that must not be defined in a data spreadsheet." fig-align="center" width="400" height="400"}
:::
::::
:::::

## Examples from Crystal Lewis (2024){.center}

::::: {layout-ncol="2"}
:::: {#first-column}
::: {style="text-align: center;font-size: 50%"}
![Lewis (2024). DOI: 10.1201/9781032622835-3](images/Lewis_fig3-3.PNG){fig-alt="Two tables comparing data structures: The left table, labeled 'Not a rectangle,' has an irregular structure with inconsistent alignment of variable names and values, making it difficult to interpret. The right table, labeled 'Rectangle,' follows a structured format with clearly defined columns for student ID, age in months, raw reading score, and standardized reading score. This contrast highlights the importance of tidy, well-structured data in research data management."}

![Lewis (2024). DOI: 10.1201/9781032622835-3](images/Lewis_fig3-4.PNG){fig-alt="Two tables comparing inconsistent and consistent data formatting. The left table, labeled 'Inconsistent column values,' contains mixed date formats (e.g., '10-12-2023,' 'Oct. 15, 2023,' 'September 15') and inconsistent categorical values for survey completion ('y,' 'Yes,' 'Y,' 'no'). The right table, labeled 'Consistent column values,' standardizes dates to 'YYYY-MM-DD' format and unifies categorical responses to 'y' and 'n.' This highlights best practices in data management for improving data clarity and usability."}
:::
::::

:::: {#second-column}
::: {style="text-align: center;font-size: 50%"}
![Lewis (2024). DOI: 10.1201/9781032622835-3](images/Lewis_fig3-5.PNG){fig-alt="Two tables comparing character and numeric variable formatting. The left table, labeled 'Character variable,' contains inconsistent age values: '24' has an extra space, '49 years old' includes unnecessary text, and '36..0' has a formatting error, causing them to be stored as text instead of numbers. The right table, labeled 'Numeric variable,' correctly stores ages as numerical values without extra spaces, text, or formatting issues. This demonstrates the importance of maintaining clean numeric data for proper analysis."}

![Lewis (2024). DOI: 10.1201/9781032622835-3](images/Lewis_fig3-6.PNG){fig-alt="Two tables comparing improper and proper data structuring. The left table, labeled 'Two things in one variable,' combines incident counts and enrollment numbers into a single column using a 'incident_rate' format (e.g., '55/250'). The right table, labeled 'Two things in two variables,' properly separates these values into distinct columns: 'incident' for the number of incidents and 'enrollment' for the total population. This demonstrates best practices in data management by ensuring each variable represents only one piece of information."}
:::
::::
:::::

## Examples from Crystal Lewis (2024)

::: {style="text-align: center;font-size: 50%"}
![Lewis (2024). DOI: 10.1201/9781032622835-3](images/Lewis_fig3-7.PNG){fig-alt="Two tables comparing implicit and explicit data entry. The left table, labeled 'Not explicit values,' omits repeated school IDs and years, assuming they apply to multiple rows, which can cause confusion in data processing. The right table, labeled 'Explicit values,' explicitly repeats the school ID and year for each row, ensuring clarity and making the dataset more machine-readable. This highlights best practices in research data management for maintaining completeness and reducing ambiguity." fig-align="center" width="500" height="200"}
:::

::: {style="text-align: center;font-size: 50%"}
![Lewis (2024). DOI: 10.1201/9781032622835-3](images/Lewis_fig3-8.PNG){fig-alt="Two tables comparing implicit and explicit variable representation. The left table, labeled 'Not explicit variables,' uses cell color to indicate treatment conditions without an explicit variable, which can be misinterpreted or lost in data processing. The right table, labeled 'Explicit variables,' adds a 'treatment' column with numerical values (0 or 1) to explicitly indicate the treatment condition for each student. This demonstrates best practices in research data management by ensuring that all meaningful information is stored as explicit variables rather than relying on formatting or visual cues." fig-align="center" width="600" height="200"}
:::


## {{< bi file-earmark-spreadsheet>}} Building accessible data tables{.center} 

::::: {layout-ncol="2" layout-valign="center"}
:::: {#first-column}
::: {style="text-align: center;font-size: 60%"} 
![A typical data table organizes the information by rows and columns](images/GoodTable.png){fig-alt="A well-structured dataset in table format, displaying experimental data for different mice. The table includes columns for 'MouseID,' 'DPI' (days post-injury), 'Condition' (MCAO), 'Region' (Contra, Ipsi, Peri), and cell counts for NeuN, Ki67, and BrdU markers. This table demonstrates a clean and organized data structure" fig-align="left" width="500" height="300"}
:::
::::

:::: {#second-column}
::: {style="text-align: center;font-size: 60%"}
### Columns
- {{< bi file-earmark-person-fill>}} [Identifier variables]{style="color:green;"}: animal ID, Time point, condition (factors or characters).
- {{< bi dropbox>}} [Analysis variables]{style="color:green;"}: score, area, number of cells, etc (numerical or categorical).
- {{< bi device-ssd-fill>}} [Variables created]{style="color:green;"} during processing (proportions, ratios, etc).

### Rows
- {{< bi clipboard-data-fill>}} [Variable values]{style="color:green;"}: entries for each column (variable). Each row corresponds to a unique observation.
:::
::::
:::::

## {{< bi file-earmark-spreadsheet>}} Wide and long table formats{.center}

::::: {layout-ncol="2" layout-valign="center"}
:::: {#first-column}
::: {style="text-align: center;font-size: 60%"} 
![A typical wide-format data table, from Lewis (2024). DOI: 10.1201/9781032622835-3](images/Lewis_fig3-14.PNG){fig-alt="Diagram illustrating the transformation of longitudinal data from separate tables into a wide format. The top two tables represent 'Wave 1 data' and 'Wave 2 data,' each containing anxiety measures ('anx1' and 'anx2') for students identified by 'stu_id.' The bottom table, labeled 'Wide format data,' consolidates both waves into a single dataset by renaming variables with wave-specific prefixes ('w1_anx1,' 'w1_anx2,' 'w2_anx1,' 'w2_anx2'). This transformation makes it easier to analyze individual-level changes over time." fig-align="left" width="600" height="350"}
:::
::::

:::: {#second-column}
::: {style="text-align: left;font-size: 70%"} 
In a [wide format]{style="color:green;"} table, [each subject]{style="text-decoration: underline;"} occupies a [single row]{style="text-decoration: underline;"} and variables are individual columns:[subject]{style="color:orange;"}, [Id1, Id2]{style="color:red;"}, [Var1, Var2]{style="color:gray;"}, [Time 1, Time2, Time3]{style="color:magenta;"}.
:::

:::{.callout-tip .smaller}
Here, columns are [responses or predictors]{style="color:green;"} in a regression. Example:   

[Cells_3D]{style="color:green;"} ~ [Cells_2D + Cells_3D]{style="color:magenta;"}.
::: 
::::
:::::

## {{< bi file-earmark-spreadsheet>}} Wide and long table formats 

::::: {layout-ncol="2" layout-valign="center"}
:::: {#first-column}
::: {style="text-align: center;font-size: 60%"} 
![A typical long-format data table, from Lewis (2024). DOI: 10.1201/9781032622835-3](images/Lewis_fig3-15.PNG){fig-alt="Diagram illustrating the transformation of longitudinal data from separate tables into a long format. The top and bottom tables represent 'Wave 1 data' and 'Wave 2 data,' each containing anxiety measures ('anx1' and 'anx2') for students identified by 'stu_id.' The right table, labeled 'Long format data,' restructures the data by adding a 'wave' column, with each row representing one student's measurements at a specific wave. This transformation optimizes the dataset for longitudinal analysis and efficient storage." fig-align="left" width="700" height="300"}
:::
::::

:::: {#second-column}
::: {style="text-align: left;font-size: 65%"} 
In a [long format]{style="color:green;"} table, [each subject]{style="text-decoration: underline;"} occupies [various rows]{style="color:green;"} and has associated observations in [different rows:]{style="text-decoration: underline;"}    

[subject]{style="color:orange;"}(repeat), [Id1, Id2 ]{style="color:red;"}(repeat), [Time (1, 2 , 3)]{style="color:magenta;"}.
:::

::: {.callout-tip .smaller}
Useful when analyzing [time-lapse data]{style="color:green;"}, grouping different condition variables in a single column. [Example:]{style="text-decoration: underline;"}   

[Cells]{style="color:green;"} ~ [TimePoint (1D, 2D, 3D)]{style="color:magenta;"}. 

Long-format is usually the first choice for data analysis.
::: 
::::
:::::

## {{< bi balloon-heart-fill>}} The best of all... {.center}  

You can use R (or Python) and [Quarto](https://quarto.org/) to convert from long to wide table format, or visceversa [tutorial](https://shanghai.hosting.nyu.edu/data/r/reshaping.html).   

::: {style="text-align: center;font-size: 60%"} 
![Long to wide format (https://tavareshugo.github.io/)](images/LongToWide.png){fig-alt="Diagram illustrating the transformation between long and wide data formats using `pivot_wider()` and `pivot_longer()`. The left table represents long format data, where each row contains a 'country', a 'year', and a corresponding 'metric' value. The right table represents wide format data, where 'year' values are spread across multiple columns (e.g., 'yr1960', 'yr1970', 'yr2010'), each containing the corresponding metric for each country. The `pivot_wider()` function converts long format to wide format, while `pivot_longer()` reverses the process, demonstrating flexible data reshaping in R." fig-align="center" width="600" height="350"}
:::

[R tutorial](https://shanghai.hosting.nyu.edu/data/r/reshaping.html)

## {{< bi file-earmark-font-fill>}} Provide metadata (README files){.center}    

::::: {layout-ncol="2" layout-valign="center"}
:::: {#first-column}
::: {style="text-align: left;font-size: 100%"} 
- Datasets are [unintelligible]{style="color:red;"} if they are not accompanied by codebooks or data dictionaries [(.txt, .md, .csv)]{style="color:green;"} describing the [variables]{style="color:green;"} of data tables. This can also take the form of a [README file]{style="color:green;"} [(.txt, .md)]{style="color:green;"} that describes their [context and content]{style="color:green;"}. 
:::
::::

::::{#second-column}
::: {style="text-align: center;font-size: 70%"} 
![Example of a readme file](images/DescriptiveMetadata_czi.png){fig-alt="Screenshot of descriptive metadata for a dataset related to PDGFR-B+ cell reactivity in a mouse model of cerebral ischemia. The text provides details on the dataset's origin, file naming conventions, experimental conditions, and image processing methods. It describes how images were derived from high-resolution Zenodo deposits and processed using ImageJ and CellProfiler. The document also outlines folder contents, including Ki67/PDGFR-B object detections and outlines, and references an OSF repository for further details." fig-align="center" width="600" height="500"}
:::
::::
:::::

# Handling images

## {{< bi card-image>}} When handling images, please consider:{.center} 

::::: {layout-ncol="2" layout-valign="center"}
:::: {#first-column}
::: {style="text-align: center;font-size: 60%"} 
![Manrique-Castano et al. (2024). DOI: DOI 10.17605/OSF.IO/3VG8J](images/BrainStaining.png){fig-alt="Fluorescence microscopy image of a coronal section of a mouse brain. The section is stained with immunofluorescence markers" fig-align="left" width="500" height="300"}
:::
::::

:::: {#second-column}
::: {style="text-align: center;font-size: 60%"}
- {{< bi card-image>}} Transform [proprietary files]{style="color:red;"} (i.e .czi) to [open formats]{style="color:green;"} with no compression (.tif).
- {{< bi gear-fill>}} Share [technical]{style="color:green;"} (acquisition parameters) and [descriptive]{style="color:green;"} (context and content) [metadata]{style="color:green;"} along with the images.
- {{< bi code-square>}} Document (i.e using [coding/scripting software]{style="color:green;"}) all procedures applied to images (resize, background subtraction, etc.). 
- {{< bi code-square>}} Perform analysis using [coding/scripting software]{style="color:green;"} to ensure reproducibility. [Avoid manual analysis]{style="color:red;"}.
:::
::::
:::::

:::{.callout-tip .smaller}
Visit this [resource](https://github.com/Alliance-RDM-GDR/RDM_BioimageFAIR) for additional information on handling and sharing images. 
:::

## {{< bi card-image>}} Transform images to open formats{.center} 

::::: {layout-ncol="2" layout-valign="center"}
:::: {#first-column}
::: {style="text-align: center;font-size: 60%"} 
![FIJI script to save .czi images as tiff. From Manrique-Castano et al. (2024). DOI: DOI 10.17605/OSF.IO/3VG8J](images/Transform_czi-tif.png){fig-alt="Screenshot of an ImageJ macro script written in JavaScript. The script automates the conversion of `.czi` microscopy image files into `.tif` format. It prompts the user to select a directory, retrieves the list of `.czi` files, and processes each file by opening it with Bio-Formats Importer. It then extracts two image channels, saving them separately as `.tif` files in an 'Images_Tiff' folder. The script ensures all files are processed systematically and closes all windows after completion." fig-align="left" width="500" height="300"}
:::
::::

:::: {#second-column}
::: {style="text-align: left;font-size: 70%"} 
You can easy [transform]{style="color:green;"} your proprietary files (.czi) to open formats (.tif) using i.e [FIJI]{style="color:green;"} [scripts](https://github.com/Alliance-RDM-GDR/RDM_OrganizeData/blob/main/resources/Transform_czi-tif.ijm).
:::
::: {.callout-caution}
Saving .czi images as .tif using FIJI will result in [metadata loss]{style="color:red;"} (archived within the .czi file). 
::: 
::::
:::::

## Keep track of metadata{.smaller} 

::::: {layout-ncol="2"}
:::: {#first-column}
#### {{< bi gear-fill>}} [Technical]{style="color:gray;"}

Export technical metadata from proprietary images (i.e .czi) as [.txt or .csv]{style="color:green;"} files (This may applied for all images in a batch).  

::: {style="text-align: center;font-size: 70%"} 
![Example of technical metadata in FIJI: *image -> show info*](images/TechnicalMetadata_czi.png){fig-alt="![Screenshot of the metadata viewer displaying technical metadata from a `.czi` microscopy image file. The metadata table includes keys and values such as 'BitsPerPixel' (14), 'DimensionOrder' (XYZCT), and 'PixelType' (uint16). Other metadata details indicate that the image has 4 channels (SizeC), a single time point (SizeT = 1), dimensions of 2752x2208 pixels (SizeX, SizeY), and a single Z-plane (SizeZ = 1). This metadata provides essential information for image processing and analysis in research microscopy." fig-align="center" width="300" height="300"}
:::
::::

:::: {#second-column}
#### {{< bi file-earmark-pdf-fill>}} [Descriptive]{style="color:orange;"}

Generate descriptive readme files to explain the [provenance and naming conventions]{style="color:green;"} of the images.

::: {style="text-align: center;font-size: 70%"} 
![Example of [descriptive metadata](https://github.com/Alliance-RDM-GDR/RDM_OrganizeData/blob/main/resources/readme_images.txt)](images/DescriptiveMetadata_czi.png){fig-alt="Screenshot of descriptive metadata for a dataset related to PDGFR-B+ cell reactivity in a mouse model of cerebral ischemia. The text provides details on the dataset's origin, file naming conventions, experimental conditions, and image processing methods. It describes how images were derived from high-resolution Zenodo deposits and processed using ImageJ and CellProfiler. The document also outlines folder contents, including Ki67/PDGFR-B object detections and outlines, and references an OSF repository for further details." fig-align="center" width="400" height="330"}
:::
::::
:::::

# Organizing (and sharing) data

## A worrying research landscape

::: {style="text-align: left;font-size: 80%"} 
We live in a pandemic of [fraudulent and irreproducible science]{style="color:red;"}. 
:::

::::: {layout-ncol="2" layout-valign="center"}
:::: {#first-column}
::: {style="text-align: left;font-size: 60%"} 
![Increase in the number of retracted articles in the last three decades](images/Economist_Retractions.png){fig-alt="A chart from The Economist titled 'Pants on fire,' illustrating the cumulative number of retracted biomedical science papers from 1996 to 2023. The graph shows an exponential increase in retractions, reaching over 15,000 by 2023. The data is sourced from Retraction Watch, covering 4,244 assessed journals. The chart highlights growing concerns about scientific integrity and the rise in retracted publications over time." fig-align="left" width="450" height="450"}
:::
::::

:::: {#second-column}
:::{style="text-align: left;font-size: 70%"}
This worrying landscape demands that, as [reputable researchers]{style="color:green;"}, we employ good [scientific practices]{style="text-decoration: underline;"} to share data and analysis procedures. 
:::
::::
:::::


## Define dataset structure {.center} 

A [structured dataset]{style="color:green;"} is the key to understanding and reusing it.

::::: {layout-ncol="2"}
:::: {#first-column}
::: {style="text-align: center;font-size: 70%"}
![From pexels.com](images/Matryoska.jpeg){fig-alt="A display of traditional Russian Matryoshka dolls, also known as nesting dolls, painted in vibrant colors."}
:::
::::

:::: {#second-column}
::: {style="text-align: center;font-size: 70%"}
![File structure](images/files.png){fig-alt="A structured directory tree representing an organized research project folder. The top-level folders include 'Code,' containing R scripts for data cleaning and analysis ('clean_raw_data.r,' 'analysis_1.r,' 'analysis_2.r'); 'Data,' which is divided into 'Raw_data' (containing raw files 'file_a.raw' and 'file_b.raw') and 'Processed_data' (containing cleaned CSV files 'file_a.csv' and 'file_b.csv'); 'Outputs,' which includes subfolders for 'Figures' and 'Models'; and a 'README.txt' file. This structure follows best practices for research data organization." width="75%"}
:::
::::
:::::

## Principles for structuring a dataset {.center}

Define a structure for the data at the [beginning]{style="color:green;"} (best) or [during]{style="color:green;"} the course of your research.

::: callout-tip
## Think about

-   {{< bi folder-fill >}} Folders/[directory structures]{style="color:green;"}
-   {{< bi filetype-tiff >}} Think about [file types/formats]{style="color:green;"}
-   {{< bi file-earmark-font-fill >}} Establish logical/descriptive [naming conventions]{style="color:green;"}
:::

Overall, ensure that the dataset structure is [logical and consistent]{style="color:green;"}, understandable to external users.


## {{< bi diagram-2-fill >}} Diving into the folder tree {.center}

::::: {layout-ncol="2" layout-valign="center"}
:::: {#first-column}
[TIER 4.0](https://www.projecttier.org/tier-protocol/protocol-4-0/root/) is a [project template]{style="color:green;"} to standardize datasets.

[Download](https://github.com/Alliance-RDM-GDR/RDM_DepositingData/blob/main/resources/TIER4.0_DatasetTemplate.zip) the project structure and adapt it to specific cases.

::::

:::: {#second-column}
::: {style="text-align: center;font-size: 50%"}
![Folder tree](images/tier.png){fig-alt="A hierarchical directory structure following the TIER Protocol 4.0 for research data organization. The top-level 'Project/' folder contains key documents such as 'The Read Me File' and 'The Report.' The 'Data/' folder is divided into 'InputData/' (with 'Input Data Files' and 'Metadata' subfolders, including 'Data Sources Guide' and 'Codebooks'), 'AnalysisData/' (with 'Analysis Data Files' and 'The Data Appendix'), and 'IntermediateData/'. The 'Scripts/' folder includes subfolders for 'ProcessingScripts/', 'DataAppendixScripts/', 'AnalysisScripts/', and 'The Master Script.' The 'Output/' folder contains 'DataAppendixOutput' and 'Results.' This structure ensures transparency and reproducibility in research data management." width="40%"}
:::
::::
:::::

## {{< bi folder-fill >}} Raw data {.center}

A [Data_Raw/]{style="color:orange;"} folder can contain:

::::: {layout-ncol="2" layout-valign="center"}
:::: {#first-column}

-   Original [images]{style="color:green;"} (.tiff, .czi)
-   Measuring device [output files]{style="color:green;"} (.txt, .csv)
-   Original registration [datasheets]{style="color:green;"} (.png, .csv, .xlxs)
::::

:::: {#second-column}
::: {style="text-align: center;font-size: 50%"}
![Folder tree](images/data_raw.png){fig-alt="A screenshot of a structured directory containing organized raw data." width="90%"}
:::
::::
:::::

## Raw Data - metadata {.center}

Include [metadata/]{style="color:orange;"} that allows the file contents to be understood and reused:

- {{< bi file-earmark-font-fill >}} Methodological and technical details.

- {{< bi file-earmark-font-fill >}} Codebooks / data dictionaries that explain variables and units. They can be [.txt](https://osf.io/9n3gh) or [.csv-xlxs](https://osf.io/925sh) files.

- {{< bi filetype-tiff >}} Instrument and acquisition parameters for images.

## {{< bi folder-fill >}} Analysis (processed) data {.center}

A [Data_Analysis/]{style="color:orange;"} folder contains [processed files]{style="color:green;"} to generate the research results.

::::: {layout-ncol="2"}
:::: {#first-column}

- Metadata similar to raw data.

- [Data_Appendix]{style="color:green;"} files showing basic descriptive statistics or data distributions.

::::

:::: {#second-column}
::: {style="text-align: center;font-size: 50%"}
![Folder tree](images/data_processed.png){fig-alt="A screenshot of a structured directory containing organized processed data." width="80%"}
:::
::::
:::::

## {{< bi folder-fill >}} Intermediate data (Optional){.center}

A [Data_Intermediate/]{style="color:orange;"} {{< bi folder-fill >}} can contain intermediate processed data, or pre-processed files as part of an analysis pipeline. For example, image 'masks' and machine learning classifiers that are used to further process images.


## {{< bi code-square >}} Scripting is the way 

::: {style="text-align: left;font-size: 80%"}
While most scientists may be more comfortable with GUIs, the current research landscape requires the use of [scripts and code]{style="color:green;"} to ensure reproducible research results.
:::

![](images/Theway.png){fig-alt="A humorous Star Wars-themed meme comparing different programming languages. The image is divided into three sections, each showing a Star Wars character wielding a lightsaber. On the left, Luke Skywalker, with an 'R' programming language logo, holds a blue lightsaber. In the center, Kylo Ren wields a red crossguard lightsaber with the GraphPad logo. On the right, Mace Windu, associated with the Python logo, holds a purple lightsaber. This meme humorously depicts the perceived roles open software has in the research landscape." fig-align="center"}

::: callout-tip
{{< bi code-square >}} Coding should be considered an [essential skill]{style="color:green;"} like other research methods.
:::

## Partners to handle code/scripts{.center}

::::: {layout-ncol="2" layout-valign="center"}
:::: {#first-column}

### {{< bi code-square>}} R-studio/Quarto (R + Python)
::: {style="text-align: center;font-size: 100%"} 
![R-studio/quarto screen](images/R-studio_Screen.jpg){fig-alt="Screenshot of an R-Studio session displaying a Quarto data analysis notebook." fig-align="center" width="500" height="300"}
:::
::::

:::: {#second-column}
### {{< bi github>}} GitHub (Version control)
::: {style="text-align: center;font-size: 100%"} 
![GitHub screen](images/GitHub_screen.jpg){fig-alt="Screenshot of a GitHub repository named 'Stroke_PDGRF-B_Reactivity,' forked from 'elalilab/Stroke_PDGRF-B_Reactivity.' The repository is public and contains directories such as 'Data_Processed' and multiple Quarto markdown files (`.qmd`) related to data analysis" fig-align="center" width="500" height="300"}
:::
::::
:::::

## With R-studio (R and Python) you can {.center}

::::: {layout-ncol="2" layout-valign="center"}
:::: {#first-column}

### {{< bi code-square>}} R-studio/Quarto (R + Python)
::: {style="text-align: center;font-size: 100%"} 
![R-studio/quarto screen](images/R-studio_Screen.jpg){fig-alt="Screenshot of an R-Studio session displaying a Quarto data analysis notebook." fig-align="center" width="500" height="300"}
:::
::::

:::: {#second-column}
:::{style="text-align: left;font-size: 75%"}
- {{< bi file-earmark-spreadsheet-fill>}} Handle [data tables and variables](https://github.com/elalilab/Stroke_PDGFR-B_Reactivity/blob/main/Widefield_10x_ROIs_CD31-Pdgfrb_Coloc.qmd) using the R [Tidyverse](https://www.tidyverse.org/).  

- {{< bi images>}} Analyze [images](https://github.com/elalilab/Stroke_PDGFR-B_Reactivity/blob/main/Confocal_40x_ROIs_Pdgfrb_Morpho_BatchScript.qmd) using Python [skimage](https://scikit-image.org/). 

- {{< bi wallet-fill>}} Process [Flow cytometry](https://github.com/elalilab/Stroke_PDGFR-B_Reactivity/blob/main/FlowCytometry_Pdgfrb_Processing.qmd) files/data using R [FlowCore](https://bioconductor.org/packages/release/bioc/html/flowCore.html) from [BioConductor](https://bioconductor.org/).

- {{< bi bandaid>}} Analyze [RNA-seq](https://www.bioconductor.org/packages/release/bioc/vignettes/DESeq2/inst/doc/DESeq2.html) data using R [DESeq2](https://bioconductor.org/packages/release/bioc/html/DESeq2.html) from [BioConductor](https://bioconductor.org/).

- {{< bi bar-chart-line-fill>}} Perform state-of-the-art [statistical modeling](https://github.com/elalilab/Stroke_PDGFR-B_Reactivity/blob/main/Widefield_5x_Ipsilateral_Gfap_IntDen.qmd) using [brms](https://paulbuerkner.com/brms/).

- And anything else you can imagine...
:::
::::
:::::

## Keep track with version control{.center}

::::: {layout-ncol="2" layout-valign="center"}
:::: {#first-column}
::: {style="text-align: center;font-size: 100%"} 
![GitHub screen](images/GitHub_screen.jpg){fig-alt="Screenshot of a GitHub repository named 'Stroke_PDGRF-B_Reactivity,' forked from 'elalilab/Stroke_PDGRF-B_Reactivity.' The repository is public and contains directories such as 'Data_Processed' and multiple Quarto markdown files (`.qmd`) related to data analysis" fig-align="center" width="500" height="300"}
:::
::::

:::: {#second-column}
:::{style="text-align: left;font-size: 75%"}
With [GitHub]{style="color:magenta;"} {{< bi github>}}  or [GitLab]{style="color:magenta;"} {{< bi gitlab>}} you can:

- {{< bi database-fill-check>}} [Store]{style="color:green;"} your code/data in a secure place and [share it]{style="color:green;"} with collaborators and the public.

- {{< bi subtract>}} Keep a [history of changes]{style="color:green;"} and version your code (v 1.0, 1.2, 2.0).

- {{< bi folder-plus>}} [Link/render]{style="color:green;"} your code in different platforms (i.e [Open Science Framework Repository](https://osf.io/)). 

- {{< bi clipboard2-pulse-fill>}} [Support other researchers]{style="color:green;"} and contribute to a culture of [open and reproducible science]{style="color:green;"}.

:::
::::
:::::

## Global supporting communities for coding {.center}

::::: {layout-ncol="2" layout-valign="center"}
:::: {#first-column}
::: {style="text-align: center;font-size: 100%"} 
![[R Ladies](https://github.com/rladies)](images/Rladies_logo.png){fig-alt="Logo of R-Ladies, a global organization that promotes gender diversity in the R programming community. The logo features a stylized gray 'R' symbol in the background, similar to the official R programming language logo, with a bold purple 'R' in the foreground. Below, the word 'Ladies' is written in gray. The logo represents an inclusive and supportive community for women and gender minorities in data science and programming with R." fig-align="center" width="300" height="300"}
:::
::::

:::: {#second-column}
::: {style="text-align: center;font-size: 100%"} 
![[Py Ladies](https://github.com/pyladies)](images/pyladies_logo.png){fig-alt="Logo of PyLadies, an international organization that promotes gender diversity in the Python programming community. The logo features a stylized illustration of a woman with red hair, black-rimmed glasses, and expressive eyes with long lashes. Below the face, the word 'pyladies' is written in a cursive, cream-colored font on a red banner. The circular logo represents an inclusive and supportive community for women and gender minorities in Python programming and data science." fig-align="center" width="300" height="300"}
:::
::::
:::::

## {{< bi folder-fill >}} Processing scripts {.center}

A [Scripts_Processing]{style="color:orange;"} folder contains code to transform the raw data for analysis:

-   Drop variables (subset the dataset)
-   Generate new variables (Perform computations, calculate averages, etc.)
-   Combine different sources of information (merge tables or files)

::: callout-tip
Consider saving the generated intermediate files in the [Data_Intermediate/]{style="color:orange;"} folder.
:::

## {{< bi lightbulb-fill >}} Keep in mind {.center}

[Logical naming conventions]{style="color:green;"} are the key to linking the raw data, processing scripts, and analysis data.


## {{< bi folder-fill >}} Analysis scripts 

::::: {layout-ncol="2"}
:::: {#first-column}
::: {style="text-align: left; font-size: 80%"}
The [Scripts_Analysis]{style="color:orange;"} folder hosts code to generate results that may be in the form of:

-   {{< bi card-image >}} Images
-   {{< bi file-bar-graph-fill >}} Figures
-   {{< bi table >}} Tables
-   {{< bi calculator-fill >}} Statistical models
:::
::::

:::: {#Second-column}
::: {style="text-align: center;font-size: 50%"}
![Folder tree](images/scripts_processing.png){fig-alt="A screenshot of a structured directory containing organized analysis data." width="90%"}
:::
::::
:::::

::: callout-tip
These scripts import and process the [analysis data]{style="color:orange;"}.
:::

## {{< bi code-slash >}} A master script? {.center}

The [Scripts/]{style="color:orange;"} folder can also contain a [master script]{style="color:green;"} that executes all other scripts, creating a fully automated pipeline.


## {{< bi folder-fill >}} The Results folder {.center}

::::: {layout-ncol="2"}
:::: {#first-column}

The [Results/]{style="color:orange;"} folder contains files generated by the analysis scripts in the form of:

-   {{< bi card-image >}} Images
-   {{< bi file-bar-graph-fill >}} Figures
-   {{< bi table >}} Tables
-   {{< bi calculator-fill >}} Statistical models
::::

:::: {#Second-column}
::: {style="text-align: center;font-size: 50%"}
![Folder tree](images/output.png){fig-alt="A screenshot of a structured directory containing scientific figures/plots" width="100%"}
:::
::::
:::::

# Write a README file

## README files{.center} 

[README files]{style="color:green;"} are guides to [understand datasets and tables]{style="color:green;"}.

::::: {layout-ncol="2" layout-valign="center"}
:::: {#first-column}
::: {style="text-align: center; font-size: 50%"}
![From https://github.com/twbs/bootstrap-rubygem](images/readme.webp){fig-alt="Screenshot of a GitHub README file for the 'Bootstrap Ruby Gem,' a library used in Ruby on Rails applications. The README file includes a badge indicating that the gem build is passing and version 4.1.1 is available. The document provides installation instructions, including how to add the gem to the Gemfile and ensure compatibility with 'sprockets-rails.' The guide references different environments, including Ruby on Rails and other Ruby frameworks. The page contains formatted code snippets for easy integration into a Rails project." fig-align="center" width="700" height="300"}
:::
::::

:::: {#second-column}
::: {style="font-size: 80%;"}
There are templates and resources to guide the generation of readme files:\
- [Creating a README file](https://blog.datadryad.org/2023/10/18/for-authors-creating-a-readme-for-rapid-data-publication/)\
- [Readme.so](https://readme.so/)\
- [Readme.ai](https://readme-ai.streamlit.app/)
:::
::::
:::::

## Contents of a readme file

:::{.r-fit-text}
Generally, a dataset readme file showcases:

-   {{< bi database-fill >}} [Dataset identifier]{style="color:green;"} showing information such as title, authors, data collection date, Geographic information.
-   {{< bi folder-fill >}} A [map of files/folders]{style="color:green;"} defining the content and hierarchy of folders and subfolders, together with naming conventions.
-   {{< bi gear-fill >}} [Methodological information]{style="color:green;"} showcasing methods for data collection/generation, analysis, and experimental conditions.

-   {{< bi sd-card-fill >}} A set of [instructions and software]{style="color:green;"} for opening, handling and reproducing research pipelines.

-   {{< bi credit-card-2-front-fill >}} [Sharing and access information]{style="color:green;"} detailing permissions and conditions of use.
:::

::: {.callout-caution collapse="true"}
## Please note
A dataset is a [standalone object]{style="text-decoration: underline;"}. Methodological information [MUST NOT]{style="color:red;"} be relegated to associated research articles.
:::

# Checklist for reproducible research

## {{< bi card-checklist >}} Commitment to reproducibility{.center}

::: {style="text-align: left;font-size: 80%"}
A [reproducible]{style="color:green;"} research project meets these characteristics:

1.  {{< bi diagram-2-fill >}} [Folders and files]{style="color:green;"} are organized in a [structured way]{style="text-decoration: underline;"} with [open file formats]{style="color:green;"} (e.g., CSV, TIFF) and consistent [naming conventions]{style="color:green;"}.

2.  {{< bi code-square >}} Processing and analysis is based on [reproducible workflows]{style="color:green;"}. Results (images, tables, figures, plots) are shared as [independent artifacts]{style="text-decoration: underline;"}.

3.  {{< bi file-earmark-text-fill >}} [README and data dictionary files]{style="color:green;"} allow the understanding of the dataset as standalone object, providing [context, methods, processing steps, and variables]{style="text-decoration: underline;"}.


:::

## In summary {.center}

A dataset is an independent research object that that can be used (and cited) [independently]{style="color:green;"} of the research article.

Better yet, think of articles as [supplements to your dataset!]{style="color:green;"}

::: callout-tip 
Visit this [resource](https://github.com/Alliance-RDM-GDR/RDM_DepositingData) for principles on deposting data into repositories.
:::


## Resources and support {.smaller}

::::: {layout-ncol="2"}
:::: {#first-column}
### Supporting material

-   [FRDR documentation](https://www.frdr-dfdr.ca/docs/en/depositing_data/)
-   [Training resources](https://alliancecan.ca/en/services/research-data-management/learning-and-training/training-resources) from the Alliance
-   [RDMkit](https://rdmkit.elixir-europe.org/sharing)
::::

:::: {#second-column}
::: {style="text-align: center;font-size: 100%"}
![This presentation is available [here](https://github.com/Alliance-RDM-GDR/RDM_OrganizeData) (English or French)](images/Presentation_QR-code.png){fig-alt="A QR code image that redirects to the presentation located in a GitHub repository." fig-align="center" width="200" height="200"}
:::
::::
:::::

### Support Services

Contact us to ensure that your data are well prepared and can be effectively shared with the research community.

-   Email: rdm-gdr\@alliancecan.ca
-   https://www.frdr-dfdr.ca/repo/

